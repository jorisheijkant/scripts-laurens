{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama test\n",
    "\n",
    "Test your locally running version of Ollama with the script below. \n",
    "\n",
    "First, import the needed modules (in this case only `ollama`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up prompt\n",
    "\n",
    "Below, set up the system prompt, be as concise as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Je krijgt een tweet te zien, laat weten of er in deze tweet sprake is van haat of niet.\n",
    "De tweet is in het Nederlands. Je kijkt specifiek naar misogyne termen (vrouwenhaat) en homohaat. \n",
    "Geef een Boolean terug, dus False of True. Geef alleen de boolean terug.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up test data\n",
    "\n",
    "Use a piece of data to test your prompt and the connection to Ollama. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet = \"Teringwijf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Ollama module code\n",
    "\n",
    "The code below creates a message array. First there's the system message with the prompt, then a user message with the tweet to be labeled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does tweet 'Teringwijf' have hate? True\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": prompt\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": test_tweet\n",
    "    }\n",
    "]\n",
    "\n",
    "response = ollama.chat(model='llama3.1', messages=messages)\n",
    "\n",
    "try:\n",
    "    ollama_response = response['message']['content']\n",
    "    print(f\"Does tweet '{test_tweet}' have hate? {ollama_response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failing to parse Ollama answer: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
